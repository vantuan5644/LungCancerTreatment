{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9m0lS_6SbDER"
   },
   "source": [
    "# TextRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0kCqGoeZokA"
   },
   "source": [
    "Automatic text summarization is the task of producing a concise and fluent summary while preserving key information\n",
    "content and overall meaning.\n",
    "\n",
    "1. Extractive Summarization\n",
    " - Identifying the important sentences or phrases from the original text and extract only those from the text.\n",
    "\n",
    "2. Abstractive Summarization\n",
    " - Generating new sentences from the original text\n",
    "\n",
    "\n",
    "3. TextRank: extractive & unsupervised text summarizatoin\n",
    " -  Concatenate text -> sentences -> sentence embeddings -> similarity matrix (between vectors) -> graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvpFrYmLa37B"
   },
   "source": [
    "### Connect to existence Github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Bvq1rQqTZ_yl",
    "outputId": "66734e75-7aab-4b01-d1e5-45d2c4cdf2e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AanlBGvAfs_h",
    "outputId": "97467391-fd3c-4671-cd6f-6ce8282d05df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/Shared drives/ZWTZWT/LungCancerTreatment\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/Shared drives/ZWTZWT/LungCancerTreatment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "IYEwN2ymaVgx",
    "outputId": "9ea2005a-0895-4c9d-aa29-75ea86b7d425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/Shared drives/ZWTZWT\n",
      "Cloning into 'LungCancerTreatment'...\n",
      "remote: Enumerating objects: 5928, done.\u001b[K\n",
      "remote: Counting objects: 100% (5928/5928), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5278/5278), done.\u001b[K\n",
      "remote: Total 5928 (delta 742), reused 5749 (delta 563), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (5928/5928), 22.71 MiB | 8.42 MiB/s, done.\n",
      "Resolving deltas: 100% (742/742), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vantuan5644/LungCancerTreatment.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bdg158tPa-5S"
   },
   "source": [
    "## TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "HNCUNmZSZokB",
    "outputId": "5e21a0bc-a4d9-4ed7-e915-e78514ee4f8f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XShSgE_Zc8Pk"
   },
   "source": [
    "### Splitting into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "iL_QwYuWZokI",
    "outputId": "960e61a7-221e-4c8c-9e2d-0f097bd80841",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_level</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Because stage 0 NSCLC is limited to the lining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>If you have stage I NSCLC, surgery may be the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>People who have stage II NSCLC and are healthy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Treatment for stage IIIA NSCLC may include som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Stage IV NSCLC is widespread when it is diagno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stage_level                                               text\n",
       "0          0.0  Because stage 0 NSCLC is limited to the lining...\n",
       "1          1.0  If you have stage I NSCLC, surgery may be the ...\n",
       "2          2.0  People who have stage II NSCLC and are healthy...\n",
       "3          3.0  Treatment for stage IIIA NSCLC may include som...\n",
       "4          4.0  Stage IV NSCLC is widespread when it is diagno..."
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ground_truths/ground_truth.csv')\n",
    "data.head()\n",
    "stage_level = data[['text', 'stage_level']].groupby('stage_level').agg({'text': lambda text: ' '.join(text),\n",
    "                                                                        })\n",
    "data = stage_level.reset_index(level=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "eRZwC9pOZokO",
    "outputId": "e354a92f-8829-447d-da32-0af385cf1692",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Because stage 0 NSCLC is limited to the lining layer of airways and has not invaded deeper into the lung tissue or other areas, it is usually curable by surgery alone.',\n",
       " 'No chemotherapy or radiation therapy is needed.',\n",
       " 'If you are healthy enough for surgery, you can usually be treated by segmentectomy or wedge resection (removal of part of the lobe of the lung).',\n",
       " 'Cancers in some locations (such as where the windpipe divides into the left and right main bronchi) may be treated with a sleeve resection, but in some cases they may be hard to remove completely without removing a lobe (lobectomy) or even an entire lung (pneumonectomy).',\n",
       " 'For some stage 0 cancers, treatments such as photodynamic therapy (PDT), laser therapy, or brachytherapy (internal radiation) may be alternatives to surgery.']"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split text into sentences\n",
    "from nltk. tokenize import sent_tokenize\n",
    "sentences = []\n",
    "for s in data['text']:\n",
    "    sentences.append(sent_tokenize(s))\n",
    "\n",
    "sentences = [y for x in sentences for y in x] # flatten list\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igCQEX_qc4Cg"
   },
   "source": [
    "### Make sentences embeddings from GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "5J3UO69aZokT",
    "outputId": "cfeb35b7-6f17-4fc3-ce82-decd193d6666",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-11 08:49:20--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2020-04-11 08:49:20--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2020-04-11 08:49:21--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  2.19MB/s    in 6m 29s  \n",
      "\n",
      "2020-04-11 08:55:50 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "# GloVe Embeddings\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHM7USfLZokY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.300d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isgpfNy1dOT0"
   },
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Wl0T21reI9g"
   },
   "source": [
    "Remove new-line character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgyY3hLDdHMn"
   },
   "outputs": [],
   "source": [
    "clean_sentences = [re.sub('\\n+', ' ', sent) for sent in sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qlvRCDXJeZ1G"
   },
   "source": [
    "Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "_SimTKmleNP1",
    "outputId": "7bac7ec4-6cce-46f1-db93-9072598acd15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VOzctStgeb38"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xSlpXEAfe0fJ"
   },
   "source": [
    "#### Make sentence vectors from word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8xEq_kwejdn"
   },
   "outputs": [],
   "source": [
    "sentence_vectors = []\n",
    "for i in clean_sentences:\n",
    "  if len(i) != 0:\n",
    "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split()))\n",
    "  else:\n",
    "    v = np.zeros((100,))\n",
    "  sentence_vectors.append(v)\n",
    "  \n",
    "assert len(sentences) == len(sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r-HgP5DPgB7a",
    "outputId": "65b5c923-6047-440d-9fdc-9ece777e9178"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ey8KRXoOfpJi"
   },
   "source": [
    "### Similarity Matrix Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77YBmx4KfkCg"
   },
   "outputs": [],
   "source": [
    "# Similarity matrix is a zero matrix with dimension (n, n)\n",
    "# We will initialize this matrix with cosine similarity of the sentences \n",
    "sim_mat = np.zeros([len(sentences), len(sentences)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrU6piFYf93o"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "  for j in range(len(sentences)):\n",
    "    if i != j:\n",
    "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O50FMp85gewD"
   },
   "source": [
    "### Applying PageRank algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaxDm6wEg-4k"
   },
   "source": [
    "#### Convert into graph\n",
    "\n",
    "We need to convert the similarity matrix **sim_mat** into a graph.\n",
    "\n",
    "The nodes of this graph will represent the sentences and the edges will represent the similarity scores between sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maSApE9NgpQj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C41UI2yogaSt"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(sim_mat)\n",
    "scores = nx.pagerank(nx_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64ecIXSRg9mK"
   },
   "source": [
    "#### Summary Extraction\n",
    "\n",
    "Extracting the top N sentences based on their rankings for summary generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwXGGHwgg7GX"
   },
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "IJUXpwEfhO5B",
    "outputId": "5997f866-839c-47a7-aa8c-69a178904374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSCLC that has spread to only one other site Cancer that is limited in the lungs and has only spread to one other site (such as the brain) is not common, but it can sometimes be treated (and even potentially cured) with surgery and/or radiation therapy to treat the area of cancer spread, followed by treatment of the cancer in the lung.\n",
      "Even if positive margins are not found, chemo is usually recommended after surgery to try to destroy any cancer cells that might have been left behind.\n",
      "As with stage I cancers, newer lab tests now being studied may help doctors find out which patients need this adjuvant treatment and which are less likely to benefit from it.\n",
      "If you are in otherwise good health, treatments such as surgery, chemotherapy (chemo), targeted therapy, immunotherapy, and radiation therapy may help you live longer and make you feel better by relieving symptoms, even though they aren’t likely to cure you.\n",
      "For people with stage I NSCLC that has a higher risk of coming back (based on size, location, or other factors), adjuvant chemotherapy after surgery may lower the risk that cancer will return.\n",
      "These cancers can be hard to treat, so taking part in a clinical trial of newer treatments may be a good option for some people.\n",
      "If you have serious medical problems that would keep you from having surgery, you may get only radiation therapy as your main treatment.\n",
      "If you have serious health problems that prevent you from having surgery, you may get stereotactic body radiation therapy (SBRT) or another type of radiation therapy as your main treatment.\n",
      "For people whose cancers have certain changes in the EGFR gene,  anti-EGFR drugs  may be used as the first treatment.\n",
      "For patients who can tolerate it, treatment usually starts with chemo, often combined with radiation therapy (also called chemoradiation).\n"
     ]
    }
   ],
   "source": [
    "# Extract top 10 sentences as the summary\n",
    "for i in range(10):\n",
    "  print(ranked_sentences[i][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJEWAeogiz6j"
   },
   "source": [
    "# Sequence-to-Sequence Modeling\n",
    "\n",
    "There are two major components of a Seq2Seq model:\n",
    "\n",
    "- Encoder: An LSTM model reads the entire input sequence wherein, at each timestep, one word is fed into the encoder. It then processes the information at every timestep and captures the contextual information present in the input sequence.\n",
    "\n",
    "![LSTM Encoder](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/61.jpg)\n",
    "\n",
    "\n",
    "- Decoder: An LSTM network which reads the entire target sequence word-by-word and predicts the same sequence offset by one timestep. **The decoder is trained to predict the next word in the sequence given the previous word.**\n",
    "\n",
    "![LSTM Decoder](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/71.jpg)\n",
    "\n",
    "\n",
    "The encoder converts the entire input sequence into a fixed length vector and then the decoder predicts the output sequence. Hence it is difficult for the encoder to memorize long sequences into a fixed length vector. We can overcome this issue by using **attention mechanism**, that aims to predict a word by looking at a few specific parts of the sequence only, rather than the entire sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWyT18zEwuj2"
   },
   "source": [
    "### Train on AmazonFineFoodReview Dataset\n",
    "\n",
    "This dataset consists of reviews of fine foods from Amazon. The data spans a period of more than 10 years, including all ~500,000 reviews up to October 2012. These reviews include product and user information, ratings, plain text review, and summary. It also includes reviews from all other Amazon categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bGB5uVfV8hU1",
    "outputId": "98c35758-1cb4-4768-8233-84f29a1e9cb0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "import os\n",
    "from bs4 import BeautifulSoup \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yErY8zhpf6Ab",
    "outputId": "32c087c4-abfc-40f0-b10b-0a2cee3c4ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/Shared drives/ZWTZWT/LungCancerTreatment/src/text_summarization\n"
     ]
    }
   ],
   "source": [
    "%cd src/text_summarization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "KrPoQYRUvR5u",
    "outputId": "e6345003-0af1-41c2-aa4e-b5495eb96bdb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a3a196f8-b429-4b0b-ac89-54375bc9c073\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-a3a196f8-b429-4b0b-ac89-54375bc9c073\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"vantuan5644\",\"key\":\"e42b59d4233ccff575f11002cc6e0c90\"}'}"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqknTNAVxuIv"
   },
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "payj1RIjys9k",
    "outputId": "6f1825ca-093f-4f73-84d2-85e5a3e18778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/Shared drives/ZWTZWT/LungCancerTreatment'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "TCtaHKItyxne",
    "outputId": "f7967b4b-692e-4117-c043-a7266fdf3a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "ref                                                  title                                               size  lastUpdated          downloadCount  \n",
      "---------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
      "snap/amazon-fine-food-reviews                        Amazon Fine Food Reviews                           242MB  2017-05-01 18:51:31          67526  \n",
      "sid321axn/amazon-alexa-reviews                       Amazon Alexa Reviews                               164KB  2018-07-31 17:45:14           7724  \n",
      "bittlingmayer/amazonreviews                          Amazon Reviews for Sentiment Analysis              493MB  2019-11-18 02:50:34          23275  \n",
      "grikomsn/amazon-cell-phones-reviews                  Amazon Cell Phones Reviews                           9MB  2019-12-26 22:21:16           6143  \n",
      "datafiniti/consumer-reviews-of-amazon-products       Consumer Reviews of Amazon Products                 16MB  2019-05-20 00:38:59          14675  \n",
      "PromptCloudHQ/amazon-reviews-unlocked-mobile-phones  Amazon Reviews: Unlocked Mobile Phones              33MB  2017-01-11 10:22:30           7408  \n",
      "bharadwaj6/kindle-reviews                            Amazon reviews: Kindle Store Category              525MB  2018-05-22 04:50:16           3199  \n",
      "atahmasb/amazon-job-skills                           AMAZON Job Skills                                    2MB  2018-03-02 04:02:20           2844  \n",
      "PromptCloudHQ/toy-products-on-amazon                 Toy Products on Amazon                               8MB  2017-09-15 19:45:36           4951  \n",
      "eswarchandt/amazon-music-reviews                     Amazon Musicual Instruments Reviews                  5MB  2020-03-29 02:59:52            518  \n",
      "gustavomodelli/forest-fires-in-brazil                Forest Fires in Brazil                              31KB  2019-08-24 16:09:16          21231  \n",
      "skillsmuggler/amazon-ratings                         Amazon - Ratings (Beauty Products)                  29MB  2018-06-24 09:49:57           1437  \n",
      "shitalkat/amazonearphonesreviews                     Amazon Earphones Reviews                           772KB  2019-07-19 04:53:11            562  \n",
      "residentmario/things-on-reddit                       Things on Reddit                                    16MB  2017-10-26 14:10:15           3837  \n",
      "mbogernetto/brazilian-amazon-rainforest-degradation  Brazilian Amazon Rainforest Degradation 1999-2019   46KB  2019-12-27 10:02:25            224  \n",
      "mpwolke/cusersmarildownloadstserofcsv                Deforestation in Federal Conservation Units.         5KB  2019-08-09 20:54:55            187  \n",
      "ak47bluestack/amazonphonedataset                     Amazon-Phone-Dataset                                 4MB  2019-07-16 07:56:15            727  \n",
      "saurav9786/amazon-product-reviews                    Amazon Product Reviews                             109MB  2020-01-14 13:25:53            236  \n",
      "prasoonkottarathil/amazon-stocks-lifetime-dataset    amazon stocks life-time dataset                    106KB  2019-11-16 05:29:21             82  \n",
      "roopalik/amazon-baby-dataset                         Amazon baby dataset                                 18MB  2017-02-01 21:01:16            572  \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list -s amazon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "uTkCsbvHy50k",
    "outputId": "86667735-1c66-4866-b2a1-6c6fa85739c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading amazon-fine-food-reviews.zip to /content/drive/Shared drives/ZWTZWT/LungCancerTreatment/src/text_summarization\n",
      "100% 241M/242M [00:03<00:00, 67.4MB/s]\n",
      "100% 242M/242M [00:03<00:00, 71.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "arnhd9J4zOD1",
    "outputId": "90041624-ff35-4710-ab15-2f77ef96520f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__init__.py',\n",
       " 'extractive_textrank.ipynb',\n",
       " 'sentences_transformer.py',\n",
       " 'attention.py',\n",
       " '.ipynb_checkpoints',\n",
       " '__pycache__',\n",
       " 'kaggle.json',\n",
       " 'amazon-fine-food-reviews.zip']"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9C9djHNzTV8"
   },
   "outputs": [],
   "source": [
    "dataset_file = os.getcwd() + '/amazon-fine-food-reviews.zip'\n",
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile(dataset_file, 'r') \n",
    "zip_ref.extractall()\n",
    "zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "BLo7JOw7zaVb",
    "outputId": "5837fa31-57b2-4cf8-ac1e-cc4a327bcc39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__init__.py',\n",
       " 'extractive_textrank.ipynb',\n",
       " 'sentences_transformer.py',\n",
       " 'attention.py',\n",
       " '.ipynb_checkpoints',\n",
       " '__pycache__',\n",
       " 'kaggle.json',\n",
       " 'amazon-fine-food-reviews.zip',\n",
       " 'Reviews.csv',\n",
       " 'database.sqlite',\n",
       " 'hashes.txt']"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ILtHegWaz9O8"
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNQAqLOF0ADj"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "Sc5hJNyP0Mg0",
    "outputId": "a37c47c5-9bd5-4e2a-e031-75bc9bbf04d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ...                                                                                                                                                                                                     Text\n",
       "0   1  ...  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...\n",
       "1   2  ...           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
       "2   3  ...  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...\n",
       "3   4  ...  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...\n",
       "4   5  ...                                                             Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvBYUN4Q0H9M"
   },
   "source": [
    "Drop duplicates and NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fipCKA2x0K-I"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'], inplace=True)  #dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)   #dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToAog3ay2_LW"
   },
   "outputs": [],
   "source": [
    "from contraction import contraction_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWv-GOPf3YUs"
   },
   "source": [
    "#### Text cleaning\n",
    " - Convert to lowercase\n",
    " - Remove HTML tags\n",
    " - Contraction mapping\n",
    " - Remove special characters\n",
    " - Remove stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "z_9eKabOgU07",
    "outputId": "a87002fe-acfc-4f82-abcc-f38b3fd1908c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Tm8PsnL3rB_"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text, remove_short_words=False, remove_xml_tag=False):\n",
    "    newString = text.lower()\n",
    "    if remove_xml_tag:\n",
    "      newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub('\\n+', ' ', newString)\n",
    "    newString = re.sub(\"[^a-zA-Z0-9]\", \" \", newString) \n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    if remove_short_words:\n",
    "      long_words=[]\n",
    "      for i in tokens:\n",
    "          if len(i) >= 3:                  # removing short word\n",
    "              long_words.append(i)   \n",
    "      return (\" \".join(long_words)).strip()\n",
    "    else:\n",
    "      return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUnpaP_z42pV"
   },
   "outputs": [],
   "source": [
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t, remove_xml_tag=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWQ7LzoX7SbE"
   },
   "outputs": [],
   "source": [
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t, remove_xml_tag=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgAc52PM7drq"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text'] = cleaned_text\n",
    "data['cleaned_summary'] = cleaned_summary\n",
    "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0Xk-4bDTJNA"
   },
   "source": [
    "#### Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZ3MfX2FS8TL"
   },
   "outputs": [],
   "source": [
    "# data[['cleaned_text', 'cleaned_summary']].to_csv('amazon_fine_food_review_cleaned', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JnuTLxCTM7A"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame('amazon_fine_food_review_cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMaikON7gxkc"
   },
   "source": [
    "Add the **START** and **END** token to the label (summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHW0F0lTfF2v"
   },
   "outputs": [],
   "source": [
    "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unkattnou42I"
   },
   "source": [
    "texts variable contains all text strings, used for creating embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVS1AfQ7uoMr"
   },
   "outputs": [],
   "source": [
    "texts = data['cleaned_text']\n",
    "texts = texts.append(data['cleaned_summary']).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ei1grOQavYnl",
    "outputId": "4836c23a-6724-4f11-ea0a-973ba8bfcec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "785258"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yrtbp0HXhbQD"
   },
   "source": [
    "#### Padding for mini-batch processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYXdCBUxhqfC"
   },
   "source": [
    "Visualize text-length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "uTevThVPhjv0",
    "outputId": "b6a7fcc2-6828-4d17-9892-ab3ed6f643ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYwa7se-pC_8"
   },
   "source": [
    "#### Use pretrained GloVe embedding layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8OmtIam2OjK"
   },
   "outputs": [],
   "source": [
    "class GlobalConfigs:\n",
    "  num_words = 150000\n",
    "  embeddings_dim = 300\n",
    "  project_root_dir = '/content/drive/Shared drives/ZWTZWT/LungCancerTreatment/'\n",
    "  max_len_text = 80\n",
    "  max_len_summary = 10\n",
    "  start_token = '_START_ '\n",
    "  end_token =  ' _END_'\n",
    "  unknown_emb = np.random.rand(1, embeddings_dim)\n",
    "  model_path = os.path.join(project_root_dir, 'src', 'text_summarization', 'models', 'weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aW7o34AMo7RT"
   },
   "outputs": [],
   "source": [
    "# Preparing GloVe\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GlobalConfigs.project_root_dir, 'glove.6B.{}d.txt'.format(GlobalConfigs.embeddings_dim)))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZX-t1HLp9b2"
   },
   "source": [
    "Make embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyxUZo9PsVAG"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=GlobalConfigs.num_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QgWCO4VAwOdq",
    "outputId": "eb53e26c-62bd-4d98-e79d-b2ff98feefc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136944 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCjWN55Ep6D4"
   },
   "outputs": [],
   "source": [
    "def get_embeddings_matrix(embeddings_dimension, embeddings_index):\n",
    "  embedding_matrix = np.zeros((len(word_index) + 1, embeddings_dimension))\n",
    "  for word, i in word_index.items():\n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "  return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fp5Pju6zzrps"
   },
   "outputs": [],
   "source": [
    "def get_embedding_layer(max_input_length, layer_name):\n",
    "  layer = Embedding(len(tokenizer.word_index) + 1, GlobalConfigs.embeddings_dim,\n",
    "                    weights=[get_embeddings_matrix(GlobalConfigs.embeddings_dim, embeddings_index)],\n",
    "                    input_length=max_input_length, trainable=False,  name=layer_name)\n",
    "  return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ZLxx3_VGIDW"
   },
   "source": [
    "#### Index2Word & Word2Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tguDlUQwJ7MB"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6CMRbaGGDB0"
   },
   "outputs": [],
   "source": [
    "def fit_text(X, Y, input_seq_max_length=None, target_seq_max_length=None):\n",
    "    if input_seq_max_length is None:\n",
    "        input_seq_max_length = GlobalConfigs.max_len_text\n",
    "    if target_seq_max_length is None:\n",
    "        target_seq_max_length = GlobalConfigs.max_len_summary\n",
    "    input_counter = Counter()\n",
    "    target_counter = Counter()\n",
    "    max_input_seq_length = 0\n",
    "    max_target_seq_length = 0\n",
    "\n",
    "    for line in X:\n",
    "        text = [word.lower() for word in line.split(' ')]\n",
    "        seq_length = len(text)\n",
    "        if seq_length > input_seq_max_length:\n",
    "            text = text[0:input_seq_max_length]\n",
    "            seq_length = len(text)\n",
    "        for word in text:\n",
    "            input_counter[word] += 1\n",
    "        max_input_seq_length = max(max_input_seq_length, seq_length)\n",
    "\n",
    "    for line in Y:\n",
    "        line2 = 'START ' + line.lower() + ' END'\n",
    "        text = [word for word in line2.split(' ')]\n",
    "        seq_length = len(text)\n",
    "        if seq_length > target_seq_max_length:\n",
    "            text = text[0:target_seq_max_length]\n",
    "            seq_length = len(text)\n",
    "        for word in text:\n",
    "            target_counter[word] += 1\n",
    "            max_target_seq_length = max(max_target_seq_length, seq_length)\n",
    "\n",
    "    input_word2idx = dict()\n",
    "    for idx, word in enumerate(input_counter.most_common(GlobalConfigs.num_words)):\n",
    "        input_word2idx[word[0]] = idx + 2\n",
    "    input_word2idx['PAD'] = 0\n",
    "    input_word2idx['UNK'] = 1\n",
    "    input_idx2word = dict([(idx, word) for word, idx in input_word2idx.items()])\n",
    "\n",
    "    target_word2idx = dict()\n",
    "    for idx, word in enumerate(target_counter.most_common(GlobalConfigs.num_words)):\n",
    "        target_word2idx[word[0]] = idx + 1\n",
    "    target_word2idx['UNK'] = 0\n",
    "\n",
    "    target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
    "    \n",
    "    num_input_tokens = len(input_word2idx)\n",
    "    num_target_tokens = len(target_word2idx)\n",
    "\n",
    "    config = dict()\n",
    "    config['input_word2idx'] = input_word2idx\n",
    "    config['input_idx2word'] = input_idx2word\n",
    "    config['target_word2idx'] = target_word2idx\n",
    "    config['target_idx2word'] = target_idx2word\n",
    "    config['num_input_tokens'] = num_input_tokens\n",
    "    config['num_target_tokens'] = num_target_tokens\n",
    "    config['max_input_seq_length'] = max_input_seq_length\n",
    "    config['max_target_seq_length'] = max_target_seq_length\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pqy3qtZzvNkb"
   },
   "source": [
    "### Custom Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c82U009U4HZx"
   },
   "outputs": [],
   "source": [
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5ZVzbZm4LVC"
   },
   "source": [
    "### Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idSG1GUQ4KYn"
   },
   "outputs": [],
   "source": [
    "def seq2seq_attention_model(hidden_dim, embedding_dim, max_len_encoder, max_len_decoder):\n",
    "  # Encoder\n",
    "  encoder_inputs = Input(shape=(max_len_encoder,))\n",
    "\n",
    "  # embedding layer\n",
    "  enc_emb =  get_embedding_layer(max_len_encoder, layer_name='emb_encoder')(encoder_inputs)\n",
    "\n",
    "  # encoder lstm 1\n",
    "  encoder_lstm1 = LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
    "  encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "  # encoder lstm 2\n",
    "  encoder_lstm2 = LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
    "  encoder_outputs, state_h, state_c = encoder_lstm2(encoder_output1)\n",
    "\n",
    "  # Set up the decoder. \n",
    "  decoder_inputs = Input(shape=(None,)) \n",
    "  dec_emb_layer = get_embedding_layer(max_len_decoder, layer_name='emb_decoder')\n",
    "  dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "  # LSTM using encoder_states as initial state\n",
    "  decoder_lstm = LSTM(hidden_dim, return_sequences=True, return_state=True) \n",
    "  decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "  # Attention Layer\n",
    "  attn_layer = AttentionLayer(name='attention_layer') \n",
    "  attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "  # Concat attention output and decoder LSTM output \n",
    "  decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "  # Dense layer\n",
    "  decoder_dense = TimeDistributed(Dense(max_len_decoder, activation='softmax')) \n",
    "  decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "  # Define the model\n",
    "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "id": "QgfsjwZV8E2i",
    "outputId": "afee2dad-371d-4d72-b727-29bf72568847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "emb_encoder (Embedding)         (None, 80, 300)      41083500    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 80, 300), (N 721200      emb_encoder[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "emb_decoder (Embedding)         (None, None, 300)    41083500    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 80, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 300),  721200      emb_decoder[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_2[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 10)     6010        concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 84,516,910\n",
      "Trainable params: 2,349,910\n",
      "Non-trainable params: 82,167,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = seq2seq_attention_model(hidden_dim=300, embedding_dim=GlobalConfigs.embeddings_dim,\n",
    "                                max_len_encoder=GlobalConfigs.max_len_text,\n",
    "                                max_len_decoder=GlobalConfigs.max_len_summary)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oq5URKgu8aVc"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tfo4sOSPD7Fc"
   },
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbC_eLxLJm-t"
   },
   "outputs": [],
   "source": [
    "config = fit_text(data['cleaned_text'], data['cleaned_summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAMv36sYKuNi"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqGloVeSummarizer:\n",
    "  def __init__(self, config, model):\n",
    "    self.max_input_seq_length = config['max_input_seq_length']\n",
    "    self.num_target_tokens = config['num_target_tokens']\n",
    "    self.max_target_seq_length = config['max_target_seq_length']\n",
    "    self.target_word2idx = config['target_word2idx']\n",
    "    self.target_idx2word = config['target_idx2word']\n",
    "    self.version = 0\n",
    "    if 'version' in config:\n",
    "      self.version = config['version']\n",
    "\n",
    "    self.word2em = dict()\n",
    "    if 'unknown_emb' in config:\n",
    "      self.unknown_emb = config['unknown_emb']\n",
    "    else:\n",
    "      self.unknown_emb = GlobalConfigs.unknown_emb\n",
    "      config['unknown_emb'] = self.unknown_emb\n",
    "\n",
    "    self.config = config\n",
    "    self.model = model\n",
    "\n",
    "  def transform_input_text(self, texts):\n",
    "    temp = []\n",
    "    for line in texts:\n",
    "        x = np.zeros(shape=(self.max_input_seq_length, GlobalConfigs.embeddings_dim))\n",
    "        for idx, word in enumerate(line.lower().split(' ')):\n",
    "            if idx >= self.max_input_seq_length:\n",
    "                break\n",
    "            emb = self.unknown_emb\n",
    "            if word in self.word2em:\n",
    "                emb = self.word2em[word]\n",
    "            x[idx, :] = emb\n",
    "        temp.append(x)\n",
    "    temp = pad_sequences(temp, maxlen=self.max_input_seq_length)\n",
    "\n",
    "    print(temp.shape)\n",
    "    return temp\n",
    "\n",
    "  def transform_target_encoding(self, texts):\n",
    "    temp = []\n",
    "    for line in texts:\n",
    "        x = []\n",
    "        for word in line.split(' '):\n",
    "            x.append(word)\n",
    "            if len(x) >= self.max_target_seq_length:\n",
    "                break\n",
    "        temp.append(x)\n",
    "\n",
    "    temp = np.array(temp)\n",
    "    print(temp.shape)\n",
    "    return temp\n",
    "\n",
    "  def generate_batch(self, x_samples, y_samples, batch_size):\n",
    "    num_batches = len(x_samples) // batch_size\n",
    "    while True:\n",
    "      for batchIdx in range(0, num_batches):\n",
    "        start = batchIdx * batch_size\n",
    "        end = (batchIdx + 1) * batch_size\n",
    "        encoder_input_data_batch = pad_sequences(x_samples[start:end], self.max_input_seq_length)\n",
    "        decoder_target_data_batch = np.zeros(shape=(batch_size, self.max_target_seq_length, self.num_target_tokens))\n",
    "        decoder_input_data_batch = np.zeros(shape=(batch_size, self.max_target_seq_length, GlobalConfigs.embeddings_dim))\n",
    "        for lineIdx, target_words in enumerate(y_samples[start:end]):\n",
    "          for idx, w in enumerate(target_words):\n",
    "            w2idx = 0  # default [UNK]\n",
    "            if w in self.word2em:\n",
    "              emb = self.unknown_emb\n",
    "              decoder_input_data_batch[lineIdx, idx, :] = emb\n",
    "            if w in self.target_word2idx:\n",
    "              w2idx = self.target_word2idx[w]\n",
    "            if w2idx != 0:\n",
    "              if idx > 0:\n",
    "                decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
    "          yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch\n",
    "\n",
    "  def fit(self, Xtrain, Ytrain, Xtest, Ytest, epochs=20, batch_size=32, model_path=GlobalConfigs.model_path):\n",
    "\n",
    "      Ytrain = self.transform_target_encoding(Ytrain)\n",
    "      Ytest = self.transform_target_encoding(Ytest)\n",
    "\n",
    "      Xtrain = self.transform_input_text(Xtrain)\n",
    "      Xtest = self.transform_input_text(Xtest)\n",
    "\n",
    "      train_gen = self.generate_batch(Xtrain, Ytrain, batch_size)\n",
    "      test_gen = self.generate_batch(Xtest, Ytest, batch_size)\n",
    "\n",
    "      train_num_batches = len(Xtrain) // batch_size\n",
    "      test_num_batches = len(Xtest) // batch_size\n",
    "\n",
    "      history = self.model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n",
    "                                          epochs=epochs,\n",
    "                                          verbose=VERBOSE, validation_data=test_gen, validation_steps=test_num_batches,\n",
    "                                          callbacks=[checkpoint])\n",
    "      self.model.save_weights(model_path)\n",
    "      return history\n",
    "\n",
    "  def summarize(self, input_text):\n",
    "        input_seq = np.zeros(shape=(1, self.max_input_seq_length, GlobalConfigs.embeddings_dim))\n",
    "        for idx, word in enumerate(input_text.lower().split(' ')):\n",
    "            if idx >= self.max_input_seq_length:\n",
    "                break\n",
    "            emb = self.unknown_emb  # default [UNK]\n",
    "            if word in self.word2em:\n",
    "                emb = self.word2em[word]\n",
    "            input_seq[0, idx, :] = emb\n",
    "        states_value = self.encoder_model.predict(input_seq)\n",
    "        target_seq = np.zeros((1, 1, GlobalConfigs.embeddings_dim))\n",
    "        target_seq[0, 0, :] = self.word2em['start']\n",
    "        target_text = ''\n",
    "        target_text_len = 0\n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
    "            sample_word = self.target_idx2word[sample_token_idx]\n",
    "            target_text_len += 1\n",
    "\n",
    "            if sample_word != 'start' and sample_word != 'end':\n",
    "                target_text += ' ' + sample_word\n",
    "\n",
    "            if sample_word == 'end' or target_text_len >= self.max_target_seq_length:\n",
    "                terminated = True\n",
    "\n",
    "            if sample_word in self.word2em:\n",
    "                target_seq[0, 0, :] = self.word2em[sample_word]\n",
    "            else:\n",
    "                target_seq[0, 0, :] = self.unknown_emb\n",
    "\n",
    "            states_value = [h, c]\n",
    "        return target_text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2Ya1fK9HiP_"
   },
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hi-5gauRiFD-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], data['cleaned_summary'],\n",
    "                                                    test_size=0.1, random_state=0, shuffle=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPab5x6ZOpSA"
   },
   "outputs": [],
   "source": [
    "summarizer = Seq2SeqGloVeSummarizer(config, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "b79ZjSeQOZrx",
    "outputId": "462910f5-fa6c-43ac-f61f-45ac881cd147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353366,)\n",
      "(39263,)\n"
     ]
    }
   ],
   "source": [
    "history = summarizer.fit(X_train, y_train, X_test, y_test, epochs=20, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_lcSNRq1Pa2d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "extractive_textrank.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
