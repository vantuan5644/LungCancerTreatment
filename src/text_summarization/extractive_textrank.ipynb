{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "extractive_textrank.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9m0lS_6SbDER"
      },
      "source": [
        "# TextRank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F0kCqGoeZokA"
      },
      "source": [
        "Automatic text summarization is the task of producing a concise and fluent summary while preserving key information\n",
        "content and overall meaning.\n",
        "\n",
        "1. Extractive Summarization\n",
        " - Identifying the important sentences or phrases from the original text and extract only those from the text.\n",
        "\n",
        "2. Abstractive Summarization\n",
        " - Generating new sentences from the original text\n",
        "\n",
        "\n",
        "3. TextRank: extractive & unsupervised text summarizatoin\n",
        " -  Concatenate text -> sentences -> sentence embeddings -> similarity matrix (between vectors) -> graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LvpFrYmLa37B"
      },
      "source": [
        "### Connect to existence Github repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bvq1rQqTZ_yl",
        "outputId": "e3642f4c-bf51-4d6e-f7ba-ebf771b8d414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AanlBGvAfs_h",
        "outputId": "5a41b954-6c54-4fb9-cca2-19cdc05ad8aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/Shared drives/ZWTZWT"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/ZWTZWT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IYEwN2ymaVgx",
        "outputId": "f9a3af03-7c14-4334-ba7c-c3f4f9fa8665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!git clone https://github.com/vantuan5644/LungCancerTreatment.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LungCancerTreatment'...\n",
            "remote: Enumerating objects: 6005, done.\u001b[K\n",
            "remote: Counting objects: 100% (6005/6005), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5324/5324), done.\u001b[K\n",
            "remote: Total 6005 (delta 795), reused 5799 (delta 594), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (6005/6005), 22.92 MiB | 11.43 MiB/s, done.\n",
            "Resolving deltas: 100% (795/795), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJsL0bnnnXeX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85470ac0-fad7-49a3-e320-02820dad604e"
      },
      "source": [
        "%cd LungCancerTreatment/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/ZWTZWT/LungCancerTreatment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bdg158tPa-5S"
      },
      "source": [
        "## TextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HNCUNmZSZokB",
        "outputId": "7dd90ee9-d96b-46ae-a92f-e8db5cbf3313",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5475P7tknnfb",
        "colab_type": "text"
      },
      "source": [
        "Choose a stage to use TextRank algorithm and inference se12seq model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRPkefdSniZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stage = 'stage 1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XShSgE_Zc8Pk"
      },
      "source": [
        "### Splitting into sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iL_QwYuWZokI",
        "outputId": "08345b38-996e-4382-bfa6-4a0b8a5cb501",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "data = pd.read_csv(f'data_crawled/{stage}.csv')\n",
        "data.head()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>snippet</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.cancer.gov/types/lung/patient/non-...</td>\n",
              "      <td>How We Treat Non-Small Cell Lung Cancer - Dana...</td>\n",
              "      <td>... tomography for mediastinal staging in pati...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.cancer.gov/types/lung/hp/non-small...</td>\n",
              "      <td>How We Treat Non-Small Cell Lung Cancer - Dana...</td>\n",
              "      <td>... tomography for mediastinal staging in pati...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.cancer.org/cancer/lung-cancer/trea...</td>\n",
              "      <td>Management of stage I and stage II non-small c...</td>\n",
              "      <td>... tomography for mediastinal staging in pati...</td>\n",
              "      <td>If you have stage I NSCLC, surgery may be the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.uptodate.com/contents/management-o...</td>\n",
              "      <td>Treatment of stage I and II non-small cell lun...</td>\n",
              "      <td>... tomography for mediastinal staging in pati...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.uptodate.com/contents/non-small-ce...</td>\n",
              "      <td>Treatment of stage I and II non-small cell lun...</td>\n",
              "      <td>... tomography for mediastinal staging in pati...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ...                                               text\n",
              "0  https://www.cancer.gov/types/lung/patient/non-...  ...                                                NaN\n",
              "1  https://www.cancer.gov/types/lung/hp/non-small...  ...                                                NaN\n",
              "2  https://www.cancer.org/cancer/lung-cancer/trea...  ...  If you have stage I NSCLC, surgery may be the ...\n",
              "3  https://www.uptodate.com/contents/management-o...  ...                                                NaN\n",
              "4  https://www.uptodate.com/contents/non-small-ce...  ...                                                NaN\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6o3_Jyin_0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stage_level = data[['text', 'stage_level']].groupby('stage_level').agg({'text': lambda text: ' '.join(text),\n",
        "#                                                                         })\n",
        "# data = stage_level.reset_index(level=0)\n",
        "# data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eRZwC9pOZokO",
        "outputId": "54685350-95f2-4914-9f78-22d4c8051833",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "# Split text into sentences\n",
        "from nltk. tokenize import sent_tokenize\n",
        "sentences = []\n",
        "for s in data[data['text'].notnull()]['text']:\n",
        "    sentences.append(sent_tokenize(s))\n",
        "\n",
        "sentences = [y for x in sentences for y in x] # flatten list\n",
        "sentences[:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['If you have stage I NSCLC, surgery may be the only treatment you need.',\n",
              " 'This may be done either by taking out the lobe of the lung that has the tumor (lobectomy) or by taking out a smaller piece of the lung (sleeve resection, segmentectomy, or wedge resection).',\n",
              " 'At least some lymph nodes in the lung and in the space between the lungs will also be removed and checked for cancer.,Segmentectomy or wedge resection is generally an option only for very small stage I cancers and for patients with other health problems that make removing the entire lobe dangerous.',\n",
              " 'Still, most surgeons believe it is better to do a lobectomy if the patient can tolerate it, as it offers the best chance for cure.,For people with stage I NSCLC that has a higher risk of coming back (based on size, location, or other factors), adjuvant chemotherapy after surgery may lower the risk that cancer will return.',\n",
              " 'But doctors aren’t always sure how to determine which people are likely to be helped by chemo.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "igCQEX_qc4Cg"
      },
      "source": [
        "### Make sentences embeddings from GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5J3UO69aZokT",
        "outputId": "612ff604-0061-422b-a1ae-204df0e1ebde",
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "# GloVe Embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-27 07:57:36--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-04-27 07:57:36--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-04-27 07:57:37--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.03MB/s    in 6m 27s  \n",
            "\n",
            "2020-04-27 08:04:04 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xHM7USfLZokY",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {}
      },
      "source": [
        "# Extract word vectors\n",
        "word_embeddings = {}\n",
        "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    word_embeddings[word] = coefs\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "isgpfNy1dOT0"
      },
      "source": [
        "#### Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Wl0T21reI9g"
      },
      "source": [
        "Remove new-line character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kgyY3hLDdHMn",
        "colab": {}
      },
      "source": [
        "clean_sentences = [re.sub('\\n+', ' ', sent) for sent in sentences]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qlvRCDXJeZ1G"
      },
      "source": [
        "Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_SimTKmleNP1",
        "outputId": "e90e8400-e065-49ed-89c2-af7932988de0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VOzctStgeb38",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(sen):\n",
        "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
        "    return sen_new\n",
        "\n",
        "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSlpXEAfe0fJ"
      },
      "source": [
        "#### Make sentence vectors from word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b8xEq_kwejdn",
        "colab": {}
      },
      "source": [
        "sentence_vectors = []\n",
        "for i in clean_sentences:\n",
        "  if len(i) != 0:\n",
        "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split()))\n",
        "  else:\n",
        "    v = np.zeros((100,))\n",
        "  sentence_vectors.append(v)\n",
        "  \n",
        "assert len(sentences) == len(sentence_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r-HgP5DPgB7a",
        "outputId": "31cb4879-e082-4ad5-dce4-23a33dd16da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentence_vectors[0].shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ey8KRXoOfpJi"
      },
      "source": [
        "### Similarity Matrix Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "77YBmx4KfkCg",
        "colab": {}
      },
      "source": [
        "# Similarity matrix is a zero matrix with dimension (n, n)\n",
        "# We will initialize this matrix with cosine similarity of the sentences \n",
        "sim_mat = np.zeros([len(sentences), len(sentences)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MrU6piFYf93o",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  for j in range(len(sentences)):\n",
        "    if i != j:\n",
        "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O50FMp85gewD"
      },
      "source": [
        "### Applying PageRank algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oaxDm6wEg-4k"
      },
      "source": [
        "#### Convert into graph\n",
        "\n",
        "We need to convert the similarity matrix **sim_mat** into a graph.\n",
        "\n",
        "The nodes of this graph will represent the sentences and the edges will represent the similarity scores between sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "maSApE9NgpQj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C41UI2yogaSt",
        "colab": {}
      },
      "source": [
        "import networkx as nx\n",
        "\n",
        "nx_graph = nx.from_numpy_array(sim_mat)\n",
        "scores = nx.pagerank(nx_graph)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "64ecIXSRg9mK"
      },
      "source": [
        "#### Summary Extraction\n",
        "\n",
        "Extracting the top N sentences based on their rankings for summary generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DwXGGHwgg7GX",
        "colab": {}
      },
      "source": [
        "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJUXpwEfhO5B",
        "outputId": "d9ee03c8-97e9-4ada-8ef4-e53d2b130ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# Extract top 10 sentences as the summary\n",
        "for i in range(3):\n",
        "  print(ranked_sentences[i][1])\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Still, most surgeons believe it is better to do a lobectomy if the patient can tolerate it, as it offers the best chance for cure.,For people with stage I NSCLC that has a higher risk of coming back (based on size, location, or other factors), adjuvant chemotherapy after surgery may lower the risk that cancer will return.\n",
            "Still, most surgeons believe it is better to do a lobectomy if the patient can tolerate it, as it offers the best chance for cure.,For people with stage I NSCLC that has a higher risk of coming back (based on size, location, or other factors), adjuvant chemotherapy after surgery may lower the risk that cancer will return.\n",
            "This could mean that some cancer has been left behind, so a second surgery might be done to try to ensure that all the cancer has been removed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rJEWAeogiz6j"
      },
      "source": [
        "# Sequence-to-Sequence Modeling\n",
        "\n",
        "There are two major components of a Seq2Seq model:\n",
        "\n",
        "- Encoder: An LSTM model reads the entire input sequence wherein, at each timestep, one word is fed into the encoder. It then processes the information at every timestep and captures the contextual information present in the input sequence.\n",
        "\n",
        "![LSTM Encoder](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/61.jpg)\n",
        "\n",
        "\n",
        "- Decoder: An LSTM network which reads the entire target sequence word-by-word and predicts the same sequence offset by one timestep. **The decoder is trained to predict the next word in the sequence given the previous word.**\n",
        "\n",
        "![LSTM Decoder](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/05/71.jpg)\n",
        "\n",
        "\n",
        "The encoder converts the entire input sequence into a fixed length vector and then the decoder predicts the output sequence. Hence it is difficult for the encoder to memorize long sequences into a fixed length vector. We can overcome this issue by using **attention mechanism**, that aims to predict a word by looking at a few specific parts of the sequence only, rather than the entire sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nWyT18zEwuj2"
      },
      "source": [
        "### Train on AmazonFineFoodReview Dataset\n",
        "\n",
        "This dataset consists of reviews of fine foods from Amazon. The data spans a period of more than 10 years, including all ~500,000 reviews up to October 2012. These reviews include product and user information, ratings, plain text review, and summary. It also includes reviews from all other Amazon categories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bGB5uVfV8hU1",
        "outputId": "983e5a1c-05d4-4a34-fba4-15823f5aeb69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "import os\n",
        "from bs4 import BeautifulSoup \n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yErY8zhpf6Ab",
        "outputId": "4791de1e-b573-4e6d-f1a8-f7f1c46eec98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd /content/drive/Shared drives/ZWTZWT/LungCancerTreatment/src/text_summarization/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/ZWTZWT/LungCancerTreatment/src/text_summarization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KrPoQYRUvR5u",
        "outputId": "9e6e3f42-7d43-4134-e30d-6bc1e27e01f1",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f4a54303-6523-48c3-b0a0-6e12fff3d0ff\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f4a54303-6523-48c3-b0a0-6e12fff3d0ff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"vantuan5644\",\"key\":\"e42b59d4233ccff575f11002cc6e0c90\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dqknTNAVxuIv",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "payj1RIjys9k",
        "outputId": "102cd747-538d-4d7e-f3f0-ae4d58874e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.getcwd()\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/Shared drives/ZWTZWT/LungCancerTreatment/src/text_summarization'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TCtaHKItyxne",
        "outputId": "f7967b4b-692e-4117-c043-a7266fdf3a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "!kaggle datasets list -s amazon\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                  title                                               size  lastUpdated          downloadCount  \n",
            "---------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "snap/amazon-fine-food-reviews                        Amazon Fine Food Reviews                           242MB  2017-05-01 18:51:31          67526  \n",
            "sid321axn/amazon-alexa-reviews                       Amazon Alexa Reviews                               164KB  2018-07-31 17:45:14           7724  \n",
            "bittlingmayer/amazonreviews                          Amazon Reviews for Sentiment Analysis              493MB  2019-11-18 02:50:34          23275  \n",
            "grikomsn/amazon-cell-phones-reviews                  Amazon Cell Phones Reviews                           9MB  2019-12-26 22:21:16           6143  \n",
            "datafiniti/consumer-reviews-of-amazon-products       Consumer Reviews of Amazon Products                 16MB  2019-05-20 00:38:59          14675  \n",
            "PromptCloudHQ/amazon-reviews-unlocked-mobile-phones  Amazon Reviews: Unlocked Mobile Phones              33MB  2017-01-11 10:22:30           7408  \n",
            "bharadwaj6/kindle-reviews                            Amazon reviews: Kindle Store Category              525MB  2018-05-22 04:50:16           3199  \n",
            "atahmasb/amazon-job-skills                           AMAZON Job Skills                                    2MB  2018-03-02 04:02:20           2844  \n",
            "PromptCloudHQ/toy-products-on-amazon                 Toy Products on Amazon                               8MB  2017-09-15 19:45:36           4951  \n",
            "eswarchandt/amazon-music-reviews                     Amazon Musicual Instruments Reviews                  5MB  2020-03-29 02:59:52            518  \n",
            "gustavomodelli/forest-fires-in-brazil                Forest Fires in Brazil                              31KB  2019-08-24 16:09:16          21231  \n",
            "skillsmuggler/amazon-ratings                         Amazon - Ratings (Beauty Products)                  29MB  2018-06-24 09:49:57           1437  \n",
            "shitalkat/amazonearphonesreviews                     Amazon Earphones Reviews                           772KB  2019-07-19 04:53:11            562  \n",
            "residentmario/things-on-reddit                       Things on Reddit                                    16MB  2017-10-26 14:10:15           3837  \n",
            "mbogernetto/brazilian-amazon-rainforest-degradation  Brazilian Amazon Rainforest Degradation 1999-2019   46KB  2019-12-27 10:02:25            224  \n",
            "mpwolke/cusersmarildownloadstserofcsv                Deforestation in Federal Conservation Units.         5KB  2019-08-09 20:54:55            187  \n",
            "ak47bluestack/amazonphonedataset                     Amazon-Phone-Dataset                                 4MB  2019-07-16 07:56:15            727  \n",
            "saurav9786/amazon-product-reviews                    Amazon Product Reviews                             109MB  2020-01-14 13:25:53            236  \n",
            "prasoonkottarathil/amazon-stocks-lifetime-dataset    amazon stocks life-time dataset                    106KB  2019-11-16 05:29:21             82  \n",
            "roopalik/amazon-baby-dataset                         Amazon baby dataset                                 18MB  2017-02-01 21:01:16            572  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uTkCsbvHy50k",
        "outputId": "c560a9f5-a80f-4ece-eadb-e49043ad5452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!kaggle datasets download -d snap/amazon-fine-food-reviews"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading amazon-fine-food-reviews.zip to /content/drive/Shared drives/ZWTZWT/LungCancerTreatment/src/text_summarization\n",
            "100% 241M/242M [00:08<00:00, 25.8MB/s]\n",
            "100% 242M/242M [00:08<00:00, 29.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "arnhd9J4zOD1",
        "outputId": "ded0a53c-67f9-4be0-835d-34a97ab2db7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "os.listdir(os.getcwd())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__init__.py',\n",
              " 'contraction.py',\n",
              " 'extractive_textrank.ipynb',\n",
              " 'sentences_transformer.py',\n",
              " 'kaggle.json',\n",
              " 'amazon-fine-food-reviews.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M9C9djHNzTV8",
        "colab": {}
      },
      "source": [
        "dataset_file = os.getcwd() + '/amazon-fine-food-reviews.zip'\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(dataset_file, 'r') \n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BLo7JOw7zaVb",
        "outputId": "a8600ca5-bfd2-4b14-9a92-7271cef1a9cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "os.listdir(os.getcwd())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__init__.py',\n",
              " 'contraction.py',\n",
              " 'extractive_textrank.ipynb',\n",
              " 'sentences_transformer.py',\n",
              " 'kaggle.json',\n",
              " 'amazon-fine-food-reviews.zip',\n",
              " 'Reviews.csv',\n",
              " 'database.sqlite',\n",
              " 'hashes.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ILtHegWaz9O8"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dNQAqLOF0ADj",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"Reviews.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sc5hJNyP0Mg0",
        "outputId": "a37c47c5-9bd5-4e2a-e031-75bc9bbf04d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                                                                                                                                                                                     Text\n",
              "0   1  ...  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...\n",
              "1   2  ...           Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
              "2   3  ...  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...\n",
              "3   4  ...  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...\n",
              "4   5  ...                                                             Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wvBYUN4Q0H9M"
      },
      "source": [
        "Drop duplicates and NA values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fipCKA2x0K-I",
        "colab": {}
      },
      "source": [
        "data.drop_duplicates(subset=['Text'], inplace=True)  #dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)   #dropping na"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ToAog3ay2_LW",
        "colab": {}
      },
      "source": [
        "from contraction import contraction_mapping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SWv-GOPf3YUs"
      },
      "source": [
        "#### Text cleaning\n",
        " - Convert to lowercase\n",
        " - Remove HTML tags\n",
        " - Contraction mapping\n",
        " - Remove special characters\n",
        " - Remove stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z_9eKabOgU07",
        "outputId": "6b7891e0-4df7-465e-ac8c-507fd628e456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHysmyMLx1FG",
        "colab_type": "text"
      },
      "source": [
        "Text cleaning: \n",
        " - Remove quote \"\n",
        " - Contraction mapping: i.e \"i'd've\": \"i would have\", \"i'll\": \"i will\"\n",
        " - Remove HTML tags\n",
        " - Remove 's\n",
        " - Remove stopwords\n",
        " - Remove punctuations and special characters\n",
        " - Remove shortwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Tm8PsnL3rB_",
        "colab": {}
      },
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"','', newString)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
        "    tokens = [w for w in newString.split() if not w in stop_words]\n",
        "    long_words=[]\n",
        "    for i in tokens:\n",
        "        if len(i)>=2:                  #removing short word\n",
        "            long_words.append(i)   \n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L80WowdCyb73",
        "colab_type": "text"
      },
      "source": [
        "Summarization cleaning: \n",
        " - Remove quote \"\n",
        " - Contraction mapping: i.e \"i'd've\": \"i would have\", \"i'll\": \"i will\"\n",
        " - Remove 's\n",
        " - Remove punctuations and special characters\n",
        " - Remove shortwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dUnpaP_z42pV",
        "colab": {}
      },
      "source": [
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"','', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newString = newString.lower()\n",
        "    tokens=newString.split()\n",
        "    newString=''\n",
        "    for i in tokens:\n",
        "        if len(i)>1:                                 \n",
        "            newString=newString+i+' '  \n",
        "    return newString\n",
        "\n",
        "#Call the above function\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTybw4lAzIVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ee6f616-8f2a-4827-e8ac-4b40cd3053b8"
      },
      "source": [
        "print(len(cleaned_text), len(cleaned_summary))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "392421 392421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YgAc52PM7drq",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=cleaned_text\n",
        "data['cleaned_summary']=cleaned_summary\n",
        "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f0Xk-4bDTJNA"
      },
      "source": [
        "#### Load cleaned data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cZ3MfX2FS8TL",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('amazon_fine_food_review_cleaned.csv'):\n",
        "  data[['cleaned_text', 'cleaned_summary']].to_csv('amazon_fine_food_review_cleaned.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5JnuTLxCTM7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "b78d9dab-89f5-4167-cbcb-1e3ec14ceb77"
      },
      "source": [
        "data = pd.read_csv('amazon_fine_food_review_cleaned.csv')\n",
        "data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better</td>\n",
              "      <td>good quality dog food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo</td>\n",
              "      <td>not as advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...</td>\n",
              "      <td>delight says it all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal</td>\n",
              "      <td>cough medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy great price wide assortment yummy taffy delivery quick taffy lover deal</td>\n",
              "      <td>great taffy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392416</th>\n",
              "      <td>great sesame chicken good better resturants eaten husband loved find recipes use</td>\n",
              "      <td>will not do without</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392417</th>\n",
              "      <td>disappointed flavor chocolate notes especially weak milk thickens flavor still disappoints worth try never buy use left gone time thanks small cans</td>\n",
              "      <td>disappointed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392418</th>\n",
              "      <td>stars small give one training session tried train dog ceaser dog treats made puppy hyper compare ingredients know little stars basic food ingredients without preservatives food coloring sweet pota...</td>\n",
              "      <td>perfect for our maltipoo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392419</th>\n",
              "      <td>best treats training rewarding dog good grooming lower calories loved doggies sweet potatoes seem favorite wet noses treat</td>\n",
              "      <td>favorite training and reward treat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392420</th>\n",
              "      <td>satisfied product advertised use cereal raw vinegar general sweetner</td>\n",
              "      <td>great honey</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>392421 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                   cleaned_text                      cleaned_summary\n",
              "0                                          bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better               good quality dog food \n",
              "1                                                                         product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo                   not as advertised \n",
              "2       confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat famil...                 delight says it all \n",
              "3                                                                                   looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal                      cough medicine \n",
              "4                                                                                                                           great taffy great price wide assortment yummy taffy delivery quick taffy lover deal                         great taffy \n",
              "...                                                                                                                                                                                                         ...                                  ...\n",
              "392416                                                                                                                         great sesame chicken good better resturants eaten husband loved find recipes use                 will not do without \n",
              "392417                                                      disappointed flavor chocolate notes especially weak milk thickens flavor still disappoints worth try never buy use left gone time thanks small cans                        disappointed \n",
              "392418  stars small give one training session tried train dog ceaser dog treats made puppy hyper compare ingredients know little stars basic food ingredients without preservatives food coloring sweet pota...            perfect for our maltipoo \n",
              "392419                                                                               best treats training rewarding dog good grooming lower calories loved doggies sweet potatoes seem favorite wet noses treat  favorite training and reward treat \n",
              "392420                                                                                                                                     satisfied product advertised use cereal raw vinegar general sweetner                         great honey \n",
              "\n",
              "[392421 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oMaikON7gxkc"
      },
      "source": [
        "Add the **START** and **END** token to the label (summary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHW0F0lTfF2v",
        "colab": {}
      },
      "source": [
        "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "unkattnou42I"
      },
      "source": [
        "texts variable contains all text strings, used for creating embeddings matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GVS1AfQ7uoMr",
        "colab": {}
      },
      "source": [
        "texts = data['cleaned_text']\n",
        "texts = texts.append(data['cleaned_summary']).to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ei1grOQavYnl",
        "outputId": "7d790159-ddec-4658-f2ff-40ed228bbf68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(texts)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyc-j0Ux4BGM",
        "colab_type": "text"
      },
      "source": [
        "Text length distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhZ0hG044DID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "ef74fa28-12f5-4718-a58a-8f88b3a18e59"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "max_len_text = 0\n",
        "max_len_summary = 0\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in data['cleaned_text']:\n",
        "  nof_words = len(str(i).split())\n",
        "  max_len_text = max(max_len_text, nof_words)\n",
        "  text_word_count.append(nof_words)\n",
        "\n",
        "for i in data['cleaned_summary']:\n",
        "  nof_words = len(str(i).split())\n",
        "  max_len_summary = max(max_len_summary, nof_words)\n",
        "\n",
        "  summary_word_count.append(nof_words)\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-tl7xaO5LEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbf0689b-e59c-459f-a32c-21aa18cfb57f"
      },
      "source": [
        "print(max_len_text, max_len_summary)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1919 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8cOKf1Z5aMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text=80 \n",
        "max_len_summary=10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oltwY2O332gw",
        "colab_type": "text"
      },
      "source": [
        "## Learn word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCjDLrNg5m4k",
        "colab_type": "text"
      },
      "source": [
        "### Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8jT5K8Z3573",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val = train_test_split(data['cleaned_text'].astype(str), data['cleaned_summary'].astype(str),\n",
        "                                         test_size=0.1, \n",
        "                                         random_state=0,\n",
        "                                         shuffle=True) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv7J85ti6XG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e3d7fd1e-1dc6-475f-bab6-9a464a8efdb8"
      },
      "source": [
        "x_tr"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "373953                                                                               scent cinnamon cloves authentic strong far many cloves overall flavor profile seemed skewed black tea portion could stronger\n",
              "367239    used waffles mix good testing kitchenaid pro line waffle maker waffles came light crispy soft moist interior cooking house smelled amazing also tested betty crocker scratch recipe waffles came bit...\n",
              "57674     small espresso enough satisfy coffee craving iced frappicino type drink cream milk barely enough sweetness coffee rich strong bitter adding teaspoon sugar fixed guess could heat hot espresso iced ...\n",
              "298415                          product work see moths flying right bought years ago work well better ones putting year good woolen clothes ruined please say something stupid like clean things putting away duh\n",
              "348092    wonder people reported work consume lot caffine use caffine products coca tea certainly positive effect without caffine jitters feel improved energy clarity look forward cup coca tea would liked i...\n",
              "                                                                                                           ...                                                                                                   \n",
              "359783    pepper created equally learned long time ago really enjoying pepper truly robust much stronger flavor regular store pepper shipped quickly happy service make sure get buying buy inferior substitut...\n",
              "358083    howdy co worker told health benefits eating pistachios always liked thought pricey nuts reading couple reviews pistachios went cost affective tasty minimal number unsplit shells problem addictive ...\n",
              "152315    originally bought busha browne jerk rub finding authentic hot wanted able marinade chicken bought sauce sauce great job quite hot rub still spicy economical rub really want really hot could marina...\n",
              "117952                                                                                                               stale thats unusual cause get time time waste money disappointed likely recorder order shame\n",
              "305711                                                   coffee blows donut shop coffees away medium roast smooth taste energizing aroma three best features absolute best cup coffee light medium roast category\n",
              "Name: cleaned_text, Length: 353178, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fOY2aeyBcC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "47a34d53-4da5-460e-b2ac-1745544bce62"
      },
      "source": [
        "y_tr"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "373953                          _START_ too many cloves  _END_\n",
              "367239                                _START_ very good  _END_\n",
              "57674                     _START_ very strong yumminess  _END_\n",
              "298415     _START_ don waste your money or your woolens  _END_\n",
              "348092                             _START_ liked it lot  _END_\n",
              "                                  ...                         \n",
              "359783                                   _START_ pepper  _END_\n",
              "358083                                _START_ good nuts  _END_\n",
              "152315    _START_ even better than the busha browne rub  _END_\n",
              "117952                         _START_ slim jims review  _END_\n",
              "305711            _START_ best donut shop coffee in cup  _END_\n",
              "Name: cleaned_summary, Length: 353178, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC7nwWOWAzO-",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR8V34xs5qWL",
        "colab_type": "text"
      },
      "source": [
        "Text Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azWcEBF55sNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj2MyRiU6MqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hc-MrnsCFaT",
        "colab_type": "text"
      },
      "source": [
        "Vocab size\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVi9QxJACHAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0ec555f-628a-4c9c-9c91-21d87fc72456"
      },
      "source": [
        "print(x_voc_size, y_voc_size)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "115125 31032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOAWEoaX64MC",
        "colab_type": "text"
      },
      "source": [
        "### Model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNcyLdo996rE",
        "colab_type": "text"
      },
      "source": [
        "Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbEfF9_w8dpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou8XwEcB-Cew",
        "colab_type": "text"
      },
      "source": [
        "3 LSTM layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_J2wLjk7D-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "ee2eaf8f-6a2a-4e54-a2a3-defe5e61a1f4"
      },
      "source": [
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=100\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_len_text,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc_size, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc_size, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention input and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model \n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 80, 100)      11512500    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 80, 300), (N 481200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 80, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    3103200     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 80, 300), (N 721200      lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 31032)  18650232    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 35,851,032\n",
            "Trainable params: 35,851,032\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IqGhi8l-MQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-kMDvszCOd9",
        "colab_type": "text"
      },
      "source": [
        "### Model fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR_MllX8-RAj",
        "colab_type": "text"
      },
      "source": [
        "Early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gw9duhD-S5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REv62kPz-nJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "43eb3fbd-ecf3-4424-a42a-f02a29bbf662"
      },
      "source": [
        "print(x_tr.shape, y_tr.shape, x_val.shape, y_val.shape)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(353178, 80) (353178, 10) (39243, 80) (39243, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD_0RsGHT95u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "fc6b5cef-a45c-49db-92ed-ed8254597bda"
      },
      "source": [
        "x_tr[0]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1011,   359,  3241,  1453,   130,   129,    65,  3241,   379,\n",
              "           8,  2863,   600, 18738,   235,    10,  1073,    36,   845,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa2OdSb_-UXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "b444769f-f425-4860-efd2-689193e61a38"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], \n",
        "                  y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,\n",
        "                  epochs=50,callbacks=[es],\n",
        "                  batch_size=128, \n",
        "                  validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 353178 samples, validate on 39243 samples\n",
            "Epoch 1/50\n",
            "   128/353178 [..............................] - ETA: 32:32WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-8834fa4ba54f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                   validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_feed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 85\u001b[0;31m         per_replica_function, args=args)\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    762\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 763\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    313\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError('The model cannot be run '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-f77bd7cfbe90>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, verbose)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# e_outputs => (batch_size, de_seq_len, en_seq_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         last_out, e_outputs, _ = K.rnn(\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0menergy_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_out_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfake_state_e\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         )\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   3103\u001b[0m         input_length=input_length)\n\u001b[1;32m   3104\u001b[0m     reachable = tf_utils.get_reachable_from_inputs([learning_phase()],\n\u001b[0;32m-> 3105\u001b[0;31m                                                    targets=[last_output])\n\u001b[0m\u001b[1;32m   3106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreachable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3107\u001b[0m         \u001b[0mlast_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mget_reachable_from_inputs\u001b[0;34m(inputs, targets)\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsumers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected Operation, Variable, or Tensor, got '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected Operation, Variable, or Tensor, got 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzrgpWzn3x1c",
        "colab_type": "text"
      },
      "source": [
        "## Use Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sYwa7se-pC_8"
      },
      "source": [
        "#### Use pretrained GloVe embedding layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q8OmtIam2OjK",
        "colab": {}
      },
      "source": [
        "class GlobalConfigs:\n",
        "  num_words = 150000\n",
        "  embeddings_dim = 300\n",
        "  project_root_dir = '/content/drive/Shared drives/ZWTZWT/LungCancerTreatment/'\n",
        "  max_len_text = 80\n",
        "  max_len_summary = 10\n",
        "  start_token = '_START_ '\n",
        "  end_token =  ' _END_'\n",
        "  unknown_emb = np.random.rand(1, embeddings_dim)\n",
        "  model_path = os.path.join(project_root_dir, 'src', 'text_summarization', 'models', 'weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aW7o34AMo7RT",
        "colab": {}
      },
      "source": [
        "# Preparing GloVe\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(GlobalConfigs.project_root_dir, 'glove.6B.{}d.txt'.format(GlobalConfigs.embeddings_dim)))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MZX-t1HLp9b2"
      },
      "source": [
        "Make embeddings matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyxUZo9PsVAG",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=GlobalConfigs.num_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgWCO4VAwOdq",
        "outputId": "eb53e26c-62bd-4d98-e79d-b2ff98feefc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 136944 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KCjWN55Ep6D4",
        "colab": {}
      },
      "source": [
        "def get_embeddings_matrix(embeddings_dimension, embeddings_index):\n",
        "  embedding_matrix = np.zeros((len(word_index) + 1, embeddings_dimension))\n",
        "  for word, i in word_index.items():\n",
        "      embedding_vector = embeddings_index.get(word)\n",
        "      if embedding_vector is not None:\n",
        "          # words not found in embedding index will be all-zeros.\n",
        "          embedding_matrix[i] = embedding_vector\n",
        "  return embedding_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fp5Pju6zzrps",
        "colab": {}
      },
      "source": [
        "def get_embedding_layer(max_input_length, layer_name):\n",
        "  layer = Embedding(len(tokenizer.word_index) + 1, GlobalConfigs.embeddings_dim,\n",
        "                    weights=[get_embeddings_matrix(GlobalConfigs.embeddings_dim, embeddings_index)],\n",
        "                    input_length=max_input_length, trainable=False,  name=layer_name)\n",
        "  return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ZLxx3_VGIDW"
      },
      "source": [
        "#### Index2Word & Word2Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tguDlUQwJ7MB",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W6CMRbaGGDB0",
        "colab": {}
      },
      "source": [
        "def fit_text(X, Y, input_seq_max_length=None, target_seq_max_length=None):\n",
        "    if input_seq_max_length is None:\n",
        "        input_seq_max_length = GlobalConfigs.max_len_text\n",
        "    if target_seq_max_length is None:\n",
        "        target_seq_max_length = GlobalConfigs.max_len_summary\n",
        "    input_counter = Counter()\n",
        "    target_counter = Counter()\n",
        "    max_input_seq_length = 0\n",
        "    max_target_seq_length = 0\n",
        "\n",
        "    for line in X:\n",
        "        text = [word.lower() for word in line.split(' ')]\n",
        "        seq_length = len(text)\n",
        "        if seq_length > input_seq_max_length:\n",
        "            text = text[0:input_seq_max_length]\n",
        "            seq_length = len(text)\n",
        "        for word in text:\n",
        "            input_counter[word] += 1\n",
        "        max_input_seq_length = max(max_input_seq_length, seq_length)\n",
        "\n",
        "    for line in Y:\n",
        "        line2 = 'START ' + line.lower() + ' END'\n",
        "        text = [word for word in line2.split(' ')]\n",
        "        seq_length = len(text)\n",
        "        if seq_length > target_seq_max_length:\n",
        "            text = text[0:target_seq_max_length]\n",
        "            seq_length = len(text)\n",
        "        for word in text:\n",
        "            target_counter[word] += 1\n",
        "            max_target_seq_length = max(max_target_seq_length, seq_length)\n",
        "\n",
        "    input_word2idx = dict()\n",
        "    for idx, word in enumerate(input_counter.most_common(GlobalConfigs.num_words)):\n",
        "        input_word2idx[word[0]] = idx + 2\n",
        "    input_word2idx['PAD'] = 0\n",
        "    input_word2idx['UNK'] = 1\n",
        "    input_idx2word = dict([(idx, word) for word, idx in input_word2idx.items()])\n",
        "\n",
        "    target_word2idx = dict()\n",
        "    for idx, word in enumerate(target_counter.most_common(GlobalConfigs.num_words)):\n",
        "        target_word2idx[word[0]] = idx + 1\n",
        "    target_word2idx['UNK'] = 0\n",
        "\n",
        "    target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
        "    \n",
        "    num_input_tokens = len(input_word2idx)\n",
        "    num_target_tokens = len(target_word2idx)\n",
        "\n",
        "    config = dict()\n",
        "    config['input_word2idx'] = input_word2idx\n",
        "    config['input_idx2word'] = input_idx2word\n",
        "    config['target_word2idx'] = target_word2idx\n",
        "    config['target_idx2word'] = target_idx2word\n",
        "    config['num_input_tokens'] = num_input_tokens\n",
        "    config['num_target_tokens'] = num_target_tokens\n",
        "    config['max_input_seq_length'] = max_input_seq_length\n",
        "    config['max_target_seq_length'] = max_target_seq_length\n",
        "\n",
        "    return config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pqy3qtZzvNkb"
      },
      "source": [
        "### Custom Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c82U009U4HZx",
        "colab": {}
      },
      "source": [
        "from attention import AttentionLayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U5ZVzbZm4LVC"
      },
      "source": [
        "### Attention Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "idSG1GUQ4KYn",
        "colab": {}
      },
      "source": [
        "def seq2seq_attention_model(hidden_dim, embedding_dim, max_len_encoder, max_len_decoder):\n",
        "  # Encoder\n",
        "  encoder_inputs = Input(shape=(max_len_encoder,))\n",
        "\n",
        "  # embedding layer\n",
        "  enc_emb =  get_embedding_layer(max_len_encoder, layer_name='emb_encoder')(encoder_inputs)\n",
        "\n",
        "  # encoder lstm 1\n",
        "  encoder_lstm1 = LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
        "  encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "  # encoder lstm 2\n",
        "  encoder_lstm2 = LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
        "  encoder_outputs, state_h, state_c = encoder_lstm2(encoder_output1)\n",
        "\n",
        "  # Set up the decoder. \n",
        "  decoder_inputs = Input(shape=(None,)) \n",
        "  dec_emb_layer = get_embedding_layer(max_len_decoder, layer_name='emb_decoder')\n",
        "  dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "  # LSTM using encoder_states as initial state\n",
        "  decoder_lstm = LSTM(hidden_dim, return_sequences=True, return_state=True) \n",
        "  decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "  # Attention Layer\n",
        "  attn_layer = AttentionLayer(name='attention_layer') \n",
        "  attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "  # Concat attention output and decoder LSTM output \n",
        "  decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "  # Dense layer\n",
        "  decoder_dense = TimeDistributed(Dense(max_len_decoder, activation='softmax')) \n",
        "  decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "  # Define the model\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QgfsjwZV8E2i",
        "outputId": "afee2dad-371d-4d72-b727-29bf72568847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "model = seq2seq_attention_model(hidden_dim=300, embedding_dim=GlobalConfigs.embeddings_dim,\n",
        "                                max_len_encoder=GlobalConfigs.max_len_text,\n",
        "                                max_len_decoder=GlobalConfigs.max_len_summary)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "emb_encoder (Embedding)         (None, 80, 300)      41083500    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 80, 300), (N 721200      emb_encoder[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "emb_decoder (Embedding)         (None, None, 300)    41083500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 80, 300), (N 721200      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 300),  721200      emb_decoder[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_1[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_2[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 10)     6010        concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 84,516,910\n",
            "Trainable params: 2,349,910\n",
            "Non-trainable params: 82,167,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oq5URKgu8aVc",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tfo4sOSPD7Fc"
      },
      "source": [
        "### Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HbC_eLxLJm-t",
        "colab": {}
      },
      "source": [
        "config = fit_text(data['cleaned_text'], data['cleaned_summary'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UAMv36sYKuNi",
        "colab": {}
      },
      "source": [
        "class Seq2SeqGloVeSummarizer:\n",
        "  def __init__(self, config, model):\n",
        "    self.max_input_seq_length = config['max_input_seq_length']\n",
        "    self.num_target_tokens = config['num_target_tokens']\n",
        "    self.max_target_seq_length = config['max_target_seq_length']\n",
        "    self.target_word2idx = config['target_word2idx']\n",
        "    self.target_idx2word = config['target_idx2word']\n",
        "    self.version = 0\n",
        "    if 'version' in config:\n",
        "      self.version = config['version']\n",
        "\n",
        "    self.word2em = dict()\n",
        "    if 'unknown_emb' in config:\n",
        "      self.unknown_emb = config['unknown_emb']\n",
        "    else:\n",
        "      self.unknown_emb = GlobalConfigs.unknown_emb\n",
        "      config['unknown_emb'] = self.unknown_emb\n",
        "\n",
        "    self.config = config\n",
        "    self.model = model\n",
        "\n",
        "  def transform_input_text(self, texts):\n",
        "    temp = []\n",
        "    for line in texts:\n",
        "        x = np.zeros(shape=(self.max_input_seq_length, GlobalConfigs.embeddings_dim))\n",
        "        for idx, word in enumerate(line.lower().split(' ')):\n",
        "            if idx >= self.max_input_seq_length:\n",
        "                break\n",
        "            emb = self.unknown_emb\n",
        "            if word in self.word2em:\n",
        "                emb = self.word2em[word]\n",
        "            x[idx, :] = emb\n",
        "        temp.append(x)\n",
        "    temp = pad_sequences(temp, maxlen=self.max_input_seq_length)\n",
        "\n",
        "    print(temp.shape)\n",
        "    return temp\n",
        "\n",
        "  def transform_target_encoding(self, texts):\n",
        "    temp = []\n",
        "    for line in texts:\n",
        "        x = []\n",
        "        for word in line.split(' '):\n",
        "            x.append(word)\n",
        "            if len(x) >= self.max_target_seq_length:\n",
        "                break\n",
        "        temp.append(x)\n",
        "\n",
        "    temp = np.array(temp)\n",
        "    print(temp.shape)\n",
        "    return temp\n",
        "\n",
        "  def generate_batch(self, x_samples, y_samples, batch_size):\n",
        "    num_batches = len(x_samples) // batch_size\n",
        "    while True:\n",
        "      for batchIdx in range(0, num_batches):\n",
        "        start = batchIdx * batch_size\n",
        "        end = (batchIdx + 1) * batch_size\n",
        "        encoder_input_data_batch = pad_sequences(x_samples[start:end], self.max_input_seq_length)\n",
        "        decoder_target_data_batch = np.zeros(shape=(batch_size, self.max_target_seq_length, self.num_target_tokens))\n",
        "        decoder_input_data_batch = np.zeros(shape=(batch_size, self.max_target_seq_length, GlobalConfigs.embeddings_dim))\n",
        "        for lineIdx, target_words in enumerate(y_samples[start:end]):\n",
        "          for idx, w in enumerate(target_words):\n",
        "            w2idx = 0  # default [UNK]\n",
        "            if w in self.word2em:\n",
        "              emb = self.unknown_emb\n",
        "              decoder_input_data_batch[lineIdx, idx, :] = emb\n",
        "            if w in self.target_word2idx:\n",
        "              w2idx = self.target_word2idx[w]\n",
        "            if w2idx != 0:\n",
        "              if idx > 0:\n",
        "                decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1\n",
        "          yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch\n",
        "\n",
        "  def fit(self, Xtrain, Ytrain, Xtest, Ytest, epochs=20, batch_size=32, model_path=GlobalConfigs.model_path):\n",
        "\n",
        "      Ytrain = self.transform_target_encoding(Ytrain)\n",
        "      Ytest = self.transform_target_encoding(Ytest)\n",
        "\n",
        "      Xtrain = self.transform_input_text(Xtrain)\n",
        "      Xtest = self.transform_input_text(Xtest)\n",
        "\n",
        "      train_gen = self.generate_batch(Xtrain, Ytrain, batch_size)\n",
        "      test_gen = self.generate_batch(Xtest, Ytest, batch_size)\n",
        "\n",
        "      train_num_batches = len(Xtrain) // batch_size\n",
        "      test_num_batches = len(Xtest) // batch_size\n",
        "\n",
        "      history = self.model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n",
        "                                          epochs=epochs,\n",
        "                                          verbose=VERBOSE, validation_data=test_gen, validation_steps=test_num_batches,\n",
        "                                          callbacks=[checkpoint])\n",
        "      self.model.save_weights(model_path)\n",
        "      return history\n",
        "\n",
        "  def summarize(self, input_text):\n",
        "        input_seq = np.zeros(shape=(1, self.max_input_seq_length, GlobalConfigs.embeddings_dim))\n",
        "        for idx, word in enumerate(input_text.lower().split(' ')):\n",
        "            if idx >= self.max_input_seq_length:\n",
        "                break\n",
        "            emb = self.unknown_emb  # default [UNK]\n",
        "            if word in self.word2em:\n",
        "                emb = self.word2em[word]\n",
        "            input_seq[0, idx, :] = emb\n",
        "        states_value = self.encoder_model.predict(input_seq)\n",
        "        target_seq = np.zeros((1, 1, GlobalConfigs.embeddings_dim))\n",
        "        target_seq[0, 0, :] = self.word2em['start']\n",
        "        target_text = ''\n",
        "        target_text_len = 0\n",
        "        terminated = False\n",
        "        while not terminated:\n",
        "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
        "            sample_word = self.target_idx2word[sample_token_idx]\n",
        "            target_text_len += 1\n",
        "\n",
        "            if sample_word != 'start' and sample_word != 'end':\n",
        "                target_text += ' ' + sample_word\n",
        "\n",
        "            if sample_word == 'end' or target_text_len >= self.max_target_seq_length:\n",
        "                terminated = True\n",
        "\n",
        "            if sample_word in self.word2em:\n",
        "                target_seq[0, 0, :] = self.word2em[sample_word]\n",
        "            else:\n",
        "                target_seq[0, 0, :] = self.unknown_emb\n",
        "\n",
        "            states_value = [h, c]\n",
        "        return target_text.strip()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t2Ya1fK9HiP_"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hi-5gauRiFD-",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], data['cleaned_summary'],\n",
        "                                                    test_size=0.1, random_state=0, shuffle=True) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NPab5x6ZOpSA",
        "colab": {}
      },
      "source": [
        "summarizer = Seq2SeqGloVeSummarizer(config, model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b79ZjSeQOZrx",
        "outputId": "462910f5-fa6c-43ac-f61f-45ac881cd147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "history = summarizer.fit(X_train, y_train, X_test, y_test, epochs=20, batch_size=4)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(353366,)\n",
            "(39263,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_lcSNRq1Pa2d",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}